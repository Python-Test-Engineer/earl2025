{"test_cases_lookup_map": {"{\"actual_output\": \"The employee with the highest total number of customers is Jane Peacock with 21 customers.\", \"context\": null, \"expected_output\": \"Peacock Jane has the most customers (she has 21 customers)\", \"hyperparameters\": null, \"input\": \"Which Employee has the Highest Total Number of Customers?\", \"retrieval_context\": null}": {"cached_metrics_data": [{"metric_data": {"name": "Correctness (GEval)", "threshold": 0.5, "success": true, "score": 1.0, "reason": "The actual output correctly identifies Jane Peacock as the employee with the highest number of customers and specifies the total as 21, matching the expected output.", "strictMode": false, "evaluationModel": "Mistral-large-latest", "evaluationCost": 0, "verboseLogs": "Criteria:\nDetermine whether the actual output is factually correct based on the expected output. \n \nEvaluation Steps:\n[\n    \"Check whether the facts in 'actual output' contradicts any facts in 'expected output\",\n    \"You should also heavily penalize situations where the actual output does not answers the question\"\n] \n \nRubric:\nNone"}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "Mistral-large-latest", "strict_mode": false, "criteria": "Determine whether the actual output is factually correct based on the expected output.", "include_reason": false, "evaluation_steps": ["Check whether the facts in 'actual output' contradicts any facts in 'expected output", "You should also heavily penalize situations where the actual output does not answers the question"], "evaluation_params": ["input", "actual_output", "expected_output"]}}]}, "{\"actual_output\": \"Here are our top customers according to invoices:\\n\\n1. **Helena Hol\\u00fd**: Total Spent - 49.62\\n2. **Richard Cunningham**: Total Spent - 47.62\\n3. **Luis Rojas**: Total Spent - 46.62\\n4. **Ladislav Kov\\u00e1cs**: Total Spent - 45.62\\n5. **Hugh O'Reilly**: Total Spent - 45.62\\n6. **Frank Ralston**: Total Spent - 43.62\\n7. **Julia Barnett**: Total Spent - 43.62\\n8. **Fynn Zimmermann**: Total Spent - 43.62\\n9. **Astrid Gruber**: Total Spent - 42.62\\n10. **Victor Stevens**: Total Spent - 42.62\", \"context\": null, \"expected_output\": \"Helena Holy, Richard Cunningham, Luis Rojas, Ladislav Kovacs, and Hugh O\\u2019Reilly are the top five customers who have spent the highest amount of money according to the invoice\", \"hyperparameters\": null, \"input\": \"Who are our top Customers according to Invoices?\", \"retrieval_context\": null}": {"cached_metrics_data": [{"metric_data": {"name": "Correctness (GEval)", "threshold": 0.5, "success": true, "score": 0.8, "reason": "The actual output correctly lists the top customers and their spending amounts, which does not contradict the expected output. However, it includes more customers than the top five mentioned in the expected output.", "strictMode": false, "evaluationModel": "Mistral-large-latest", "evaluationCost": 0, "verboseLogs": "Criteria:\nDetermine whether the actual output is factually correct based on the expected output. \n \nEvaluation Steps:\n[\n    \"Check whether the facts in 'actual output' contradicts any facts in 'expected output\",\n    \"You should also heavily penalize situations where the actual output does not answers the question\"\n] \n \nRubric:\nNone"}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "Mistral-large-latest", "strict_mode": false, "criteria": "Determine whether the actual output is factually correct based on the expected output.", "include_reason": false, "evaluation_steps": ["Check whether the facts in 'actual output' contradicts any facts in 'expected output", "You should also heavily penalize situations where the actual output does not answers the question"], "evaluation_params": ["input", "actual_output", "expected_output"]}}]}}}