{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Enrichment, Data Normalization and Standardization\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Introduction\n",
    "2. Examples\n",
    "3. References and Further Reading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from rich.console import Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff8700; text-decoration-color: #ff8700\">Using OpenAI API key: sk-proj-Tc_Y</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;208mUsing OpenAI API key: sk-proj-Tc_Y\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console = Console()\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "console.print(f\"[dark_orange]Using OpenAI API key: {OPENAI_API_KEY[:12]}[/]\")\n",
    "# Set up OpenAI API key\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_value(dict_variable):\n",
    "    \"\"\"The function clean takes a dictionary (dict_variable) as input and returns the value of the first key-value pair in the dictionary.\n",
    "\n",
    "    Here's a breakdown:\n",
    "\n",
    "    iter(dict_variable.values()) creates an iterator over the dictionary's values.\n",
    "    next(...) retrieves the first value from the iterator.\n",
    "    So, if you have a dictionary like {'a': 1, 'b': 2, 'c': 3}, calling clean on it would return 1, which is the value associated with the first key 'a'.\n",
    "\n",
    "    Note that this function assumes the dictionary is not empty. If the dictionary is empty, next will raise a StopIteration exception.\n",
    "    \"\"\"\n",
    "    return next(iter(dict_variable.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 1: Analyzing and Classifying News Articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************I24A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      2\u001b[39m news_article = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m[ARTICLE 1]\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33mThe stock market saw significant gains today as tech companies reported strong quarterly earnings. \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[33mthe qualities which have made one of the greatest gymnasts of all time on her return to the Olympics.\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Analyze and classify the article\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a helpful assistant that analyzes and classifies news articles.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAnalyze this news article and classify it into one of these categories: Technology, Sports, Other. Output in JSON form: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnews_article\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mrcra\\Desktop\\ai-agents-in-the-data-pipeline\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mrcra\\Desktop\\ai-agents-in-the-data-pipeline\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mrcra\\Desktop\\ai-agents-in-the-data-pipeline\\venv\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mrcra\\Desktop\\ai-agents-in-the-data-pipeline\\venv\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************I24A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "# Sample news article\n",
    "news_article = \"\"\"\n",
    "[ARTICLE 1]\n",
    "The stock market saw significant gains today as tech companies reported strong quarterly earnings. \n",
    "Apple, Microsoft, and Amazon all beat analyst expectations, driving the NASDAQ to new highs. \n",
    "Meanwhile, concerns about inflation have eased slightly following the Federal Reserve's latest statement.\n",
    "\n",
    "[ARTICLE 2]\n",
    "Simone Biles fought through pain in her calf on Sunday to post an impressive all-around score and display \n",
    "the qualities which have made one of the greatest gymnasts of all time on her return to the Olympics.\n",
    "\"\"\"\n",
    "\n",
    "# Analyze and classify the article\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that analyzes and classifies news articles.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Analyze this news article and classify it into one of these categories: Technology, Sports, Other. Output in JSON form: {news_article}\",\n",
    "        },\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how Gen AI can analyze a news article, classify it into categories, and provide a summary. This is useful for data engineers working with large collections of news articles, helping to organize and extract key information efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 1: Filling Missing Text Data (Text Data Imputation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                   Title               Author      Genre\n",
      "0       The Great Gatsby  F. Scott Fitzgerald      Novel\n",
      "1  To Kill a Mockingbird           Harper Lee    Fiction\n",
      "2                   1984        George Orwell  Dystopian\n",
      "3    Pride and Prejudice                 None    Romance\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset with missing text data\n",
    "data = {\n",
    "    \"Title\": [\n",
    "        \"The Great Gatsby\",\n",
    "        \"To Kill a Mockingbird\",\n",
    "        \"1984\",\n",
    "        \"Pride and Prejudice\",\n",
    "    ],\n",
    "    \"Author\": [\"F. Scott Fitzgerald\", \"Harper Lee\", \"George Orwell\", None],\n",
    "    \"Genre\": [\"Novel\", \"Fiction\", \"Dystopian\", \"Romance\"],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Title               Author      Genre\n",
      "0       The Great Gatsby  F. Scott Fitzgerald      Novel\n",
      "1  To Kill a Mockingbird           Harper Lee    Fiction\n",
      "2                   1984        George Orwell  Dystopian\n",
      "3    Pride and Prejudice          Jane Austen    Romance\n"
     ]
    }
   ],
   "source": [
    "# Function to predict missing author\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"Author\"] is None:\n",
    "        prompt = \"Who is the author of this book? Return only the answer. {}\".format(\n",
    "            row[\"Title\"]\n",
    "        )\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        df.at[index, \"Author\"] = response.choices[0].message.content\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "              Book Title               Author      Genre\n",
      "0                   None  F. Scott Fitzgerald      Novel\n",
      "1  To Kill a Mockingbird           Harper Lee    Fiction\n",
      "2                   1984        George Orwell  Dystopian\n",
      "3    Pride and Prejudice                 None    Romance\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset with missing text data\n",
    "data = {\n",
    "    \"Book Title\": [None, \"To Kill a Mockingbird\", \"1984\", \"Pride and Prejudice\"],\n",
    "    \"Author\": [\"F. Scott Fitzgerald\", \"Harper Lee\", \"George Orwell\", None],\n",
    "    \"Genre\": [\"Novel\", \"Fiction\", \"Dystopian\", \"Romance\"],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given this information: [{'Author': 'F. Scott Fitzgerald'}, {'Genre': 'Novel'}]. What is the Book Title? Return only the answer\n",
      "Given this information: [{'Book Title': 'Pride and Prejudice'}, {'Genre': 'Romance'}]. What is the Author? Return only the answer\n",
      "              Book Title               Author      Genre\n",
      "0       The Great Gatsby  F. Scott Fitzgerald      Novel\n",
      "1  To Kill a Mockingbird           Harper Lee    Fiction\n",
      "2                   1984        George Orwell  Dystopian\n",
      "3    Pride and Prejudice          Jane Austen    Romance\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    for col in df.columns:\n",
    "        if row[col] is None:\n",
    "            prompt = \"Given this information: {}. What is the {}? Return only the answer\".format(\n",
    "                [\n",
    "                    {col_loop: row[col_loop]}\n",
    "                    for col_loop in df.columns\n",
    "                    if col_loop != col\n",
    "                ],\n",
    "                col,\n",
    "            )\n",
    "            print(prompt)\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "\n",
    "            df.at[index, col] = response.choices[0].message.content\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example2'></a>\n",
    "\n",
    "## 2. Example 2: Filling Missing Numerical Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "  Product  Price  Quantity\n",
      "0       A  10.99     100.0\n",
      "1       B    NaN     150.0\n",
      "2       C  15.50       NaN\n",
      "3       D   8.75     200.0\n",
      "4       E    NaN     175.0\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset with missing numerical data\n",
    "data_num = pd.DataFrame(\n",
    "    {\n",
    "        \"Product\": [\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    "        \"Price\": [10.99, np.nan, 15.50, 8.75, np.nan],\n",
    "        \"Quantity\": [100, 150, np.nan, 200, 175],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with filled missing values:\n",
      "  Product  Price  Quantity\n",
      "0       A  10.99     100.0\n",
      "1       B  25.99     150.0\n",
      "2       C  15.50     100.0\n",
      "3       D   8.75     200.0\n",
      "4       E  29.99     175.0\n"
     ]
    }
   ],
   "source": [
    "# Function to fill missing numerical data\n",
    "def fill_missing_numerical(row):\n",
    "    if pd.isna(row[\"Price\"]) or pd.isna(row[\"Quantity\"]):\n",
    "        prompt = f\"Predict the missing values for this product: Product: {row['Product']}, Price: {row['Price']}, Quantity: {row['Quantity']}. Consider market trends and product characteristics. Output in JSON form.\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "\n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "\n",
    "        if pd.isna(row[\"Price\"]):\n",
    "            row[\"Price\"] = float(result.get(\"Price\", row[\"Price\"]))\n",
    "        if pd.isna(row[\"Quantity\"]):\n",
    "            row[\"Quantity\"] = int(result.get(\"Quantity\", row[\"Quantity\"]))\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "# Apply the function to each row\n",
    "data_num_filled = data_num.apply(fill_missing_numerical, axis=1)\n",
    "\n",
    "print(\"Dataset with filled missing values:\")\n",
    "print(data_num_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "     Product  Price  Number of days since release\n",
      "0  iPhone 12  599.0                        1374.0\n",
      "1  iPhone 11  499.0                        1773.0\n",
      "2   iPhone X  399.0                           NaN\n",
      "3   iPhone 7  299.0                        2872.0\n",
      "4  iPhone 14    NaN                         681.0\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset with missing numerical data\n",
    "data_num = pd.DataFrame(\n",
    "    {\n",
    "        \"Product\": [\"iPhone 12\", \"iPhone 11\", \"iPhone X\", \"iPhone 7\", \"iPhone 14\"],\n",
    "        \"Price\": [599, 499, 399, 299, np.nan],\n",
    "        \"Number of days since release\": [1374, 1773, np.nan, 2872, 681],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with filled missing values:\n",
      "     Product   Price Number of days since release\n",
      "0  iPhone 12   599.0                       1374.0\n",
      "1  iPhone 11   499.0                       1773.0\n",
      "2   iPhone X   399.0                         1500\n",
      "3   iPhone 7   299.0                       2872.0\n",
      "4  iPhone 14  999.99                        681.0\n"
     ]
    }
   ],
   "source": [
    "# Function to fill missing numerical data\n",
    "def fill_missing_numerical(row):\n",
    "    if pd.isna(row[\"Price\"]) or pd.isna(row[\"Number of days since release\"]):\n",
    "        prompt = f\"Predict the missing values for this product: Product: {row['Product']}, Price: {row['Price']}, Quantity: {row['Number of days since release']}. Consider market trends and product characteristics. You must provide a value. Only return the value, nothing else\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "\n",
    "        if pd.isna(row[\"Price\"]):\n",
    "            row[\"Price\"] = result\n",
    "        if pd.isna(row[\"Number of days since release\"]):\n",
    "            row[\"Number of days since release\"] = result\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "# Apply the function to each row\n",
    "data_num_filled = data_num.apply(fill_missing_numerical, axis=1)\n",
    "\n",
    "print(\"Dataset with filled missing values:\")\n",
    "print(data_num_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example3'></a>\n",
    "\n",
    "## 2. Example 3: Filling Missing Time Series Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "        Date  Temperature\n",
      "0 2023-01-01         20.0\n",
      "1 2023-01-02         22.0\n",
      "2 2023-01-03          NaN\n",
      "3 2023-01-04         19.0\n",
      "4 2023-01-05         18.0\n",
      "5 2023-01-06          NaN\n",
      "6 2023-01-07         23.0\n",
      "7 2023-01-08         25.0\n",
      "8 2023-01-09         24.0\n",
      "9 2023-01-10          NaN\n"
     ]
    }
   ],
   "source": [
    "# Sample time series dataset with missing values\n",
    "dates = pd.date_range(start=\"2023-01-01\", end=\"2023-01-10\", freq=\"D\")\n",
    "data_ts = pd.DataFrame(\n",
    "    {\"Date\": dates, \"Temperature\": [20, 22, np.nan, 19, 18, np.nan, 23, 25, 24, np.nan]}\n",
    ")\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(data_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in the missing temperature values in this time series data. Consider trends and patterns. Data: [{\"Date\":\"2023-01-01T00:00:00.000\",\"Temperature\":20.0},{\"Date\":\"2023-01-02T00:00:00.000\",\"Temperature\":22.0},{\"Date\":\"2023-01-03T00:00:00.000\",\"Temperature\":null},{\"Date\":\"2023-01-04T00:00:00.000\",\"Temperature\":19.0},{\"Date\":\"2023-01-05T00:00:00.000\",\"Temperature\":18.0},{\"Date\":\"2023-01-06T00:00:00.000\",\"Temperature\":null},{\"Date\":\"2023-01-07T00:00:00.000\",\"Temperature\":23.0},{\"Date\":\"2023-01-08T00:00:00.000\",\"Temperature\":25.0},{\"Date\":\"2023-01-09T00:00:00.000\",\"Temperature\":24.0},{\"Date\":\"2023-01-10T00:00:00.000\",\"Temperature\":null}]. Output in JSON form.\n"
     ]
    }
   ],
   "source": [
    "# Function to fill missing time series data\n",
    "def fill_missing_timeseries(data):\n",
    "    context = data.to_json(orient=\"records\", date_format=\"iso\")\n",
    "    prompt = f\"Fill in the missing temperature values in this time series data. Consider trends and patterns. Data: {context}. Output in JSON form.\"\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    filled_data = pd.DataFrame(get_first_value(result))\n",
    "    filled_data[\"Date\"] = pd.to_datetime(filled_data[\"Date\"])\n",
    "\n",
    "    return filled_data\n",
    "\n",
    "\n",
    "# Apply the function to the dataset\n",
    "data_ts_filled = fill_missing_timeseries(data_ts)\n",
    "\n",
    "print(\"Dataset with filled missing values:\")\n",
    "print(data_ts_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_ts[\"Date\"], data_ts[\"Temperature\"], marker=\"o\")\n",
    "plt.title(\"Temperature Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_ts_filled[\"Date\"], data_ts_filled[\"Temperature\"], marker=\"o\")\n",
    "plt.title(\"Temperature Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 4: Converting Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Sample data with mixed data types\u001b[39;00m\n\u001b[32m      2\u001b[39m data = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mID\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m001\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m002\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m003\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m00006\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m10.5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m15\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtwenty\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mthirty-one\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m2023-01-01\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m01/15/2023\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMarch 1, 2023\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDec 4,, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m94\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mpd\u001b[49m.DataFrame(data)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOriginal data:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Sample data with mixed data types\n",
    "data = {\n",
    "    \"ID\": [\"001\", \"002\", \"003\", \"00006\"],\n",
    "    \"Value\": [\"10.5\", \"15\", \"twenty\", \"thirty-one\"],\n",
    "    \"Date\": [\"2023-01-01\", \"01/15/2023\", \"March 1, 2023\", \"Dec 4,, '94\"],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gen AI to convert data types\n",
    "prompt = f\"Convert the following data to appropriate data types. ID should be integer, Value should be float (convert 'twenty' to 20.0), and Date should be in ISO format (YYYY-MM-DD). Output in JSON form:\\n{df.to_json()}\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "converted_data = json.loads(response.choices[0].message.content)\n",
    "print(\"\\nConverted data:\")\n",
    "print(json.dumps(converted_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with converted values\n",
    "df_converted = pd.DataFrame(converted_data)\n",
    "df_converted[\"ID\"] = df_converted[\"ID\"].astype(int)\n",
    "df_converted[\"Value\"] = df_converted[\"Value\"].astype(float)\n",
    "df_converted[\"Date\"] = pd.to_datetime(df_converted[\"Date\"])\n",
    "print(\"\\nFinal converted DataFrame:\")\n",
    "print(df_converted)\n",
    "print(\"\\nData types:\")\n",
    "print(df_converted.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = [\n",
    "    \"123 Main St, Apt 4, New York, NY 10001\",\n",
    "    \"60601 456 Elm Avenue, Chicago\",\n",
    "    \"Los Angeles 789 Oak Rd Suite 100 Cali 90001\",\n",
    "]\n",
    "\n",
    "prompt = f\"Normalize these addresses to a standard format: {addresses}. Output in JSON form with keys: street, city, state, zip.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_first_value(json.loads(response.choices[0].message.content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example2'></a>\n",
    "\n",
    "## 2. Example 5: Normalizing Text Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "    descriptions\n",
      "0      RED apple\n",
      "1   Green BANANA\n",
      "2   yellow Lemon\n",
      "3  ORANGE orange\n"
     ]
    }
   ],
   "source": [
    "# Sample data with inconsistent text formatting\n",
    "data = {\"descriptions\": [\"RED apple\", \"Green BANANA\", \"yellow Lemon\", \"ORANGE orange\"]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized descriptions:\n",
      "['Red Apple', 'Green Banana', 'Yellow Lemon', 'Orange Orange']\n"
     ]
    }
   ],
   "source": [
    "# Use Gen AI to normalize text data\n",
    "prompt = f\"Normalize these fruit descriptions by capitalizing only the first letter of each word: {df['descriptions'].tolist()}. Output in JSON form\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "normalized_descriptions = json.loads(response.choices[0].message.content)\n",
    "print(\"Normalized descriptions:\")\n",
    "print(get_first_value(normalized_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the DataFrame with normalized descriptions\n",
    "df[\"normalized_descriptions\"] = clean(normalized_descriptions)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example3'></a>\n",
    "\n",
    "## 2. Example 6: Standardizing Categorical Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "               categories\n",
      "0                      IT\n",
      "1  Information Technology\n",
      "2                    Tech\n",
      "3                    I.T.\n",
      "4        Information Tech\n",
      "5                   Cyber\n",
      "6            Cyberscryity\n",
      "7           Cybersecurity\n"
     ]
    }
   ],
   "source": [
    "# Sample data with inconsistent categorical values\n",
    "data = {\n",
    "    \"categories\": [\n",
    "        \"IT\",\n",
    "        \"Information Technology\",\n",
    "        \"Tech\",\n",
    "        \"I.T.\",\n",
    "        \"Information Tech\",\n",
    "        \"Cyber\",\n",
    "        \"Cyberscryity\",\n",
    "        \"Cybersecurity\",\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized categories:\n",
      "{'categories': ['IT', 'IT', 'IT', 'IT', 'IT', 'Cybersecurity', 'Cybersecurity', 'Cybersecurity']}\n"
     ]
    }
   ],
   "source": [
    "# Use Gen AI to standardize categorical data\n",
    "prompt = f\"Standardize these category names to a single consistent format (either 'IT' or 'Cybersecurity'): {df['categories'].tolist()}. Output in JSON form\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "standardized_categories = json.loads(response.choices[0].message.content)\n",
    "print(\"Standardized categories:\")\n",
    "print(standardized_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame:\n",
      "               categories standardized_categories\n",
      "0                      IT                      IT\n",
      "1  Information Technology                      IT\n",
      "2                    Tech                      IT\n",
      "3                    I.T.                      IT\n",
      "4        Information Tech                      IT\n",
      "5                   Cyber           Cybersecurity\n",
      "6            Cyberscryity           Cybersecurity\n",
      "7           Cybersecurity           Cybersecurity\n"
     ]
    }
   ],
   "source": [
    "# Update the DataFrame with standardized categories\n",
    "df[\"standardized_categories\"] = get_first_value(standardized_categories)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 7: Standardizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: iPhone 12 Pro Max 256GB\n",
      "Standardized: Apple iPhone 12 Pro Max 256GB\n",
      "\n",
      "Original: Apple iphone 12 pro max (256 gb)\n",
      "Standardized: Apple iPhone 12 Pro Max 256GB\n",
      "\n",
      "Original: 12 Pro Max iPhone - 256GB\n",
      "Standardized: Apple\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample product names\n",
    "product_names = [\n",
    "    \"iPhone 12 Pro Max 256GB\",\n",
    "    \"Apple iphone 12 pro max (256 gb)\",\n",
    "    \"12 Pro Max iPhone - 256GB\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to standardize product name\n",
    "def standardize_product_name(name):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a product name standardization assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Standardize this product name to the format 'Brand Model Storage'. Product name: {name}. Output in JSON form.\",\n",
    "            },\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# Standardize product names\n",
    "standardized_names = [standardize_product_name(name) for name in product_names]\n",
    "\n",
    "# Display results\n",
    "for original, standardized in zip(product_names, standardized_names):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Standardized: {get_first_value(standardized)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer: John Doe, 35 years old, buys electronics frequently\n",
      "Category: Tech Enthusiast\n",
      "\n",
      "Customer: Jane Smith, 28 years old, purchases cosmetics monthly\n",
      "Category: Beauty Lover\n",
      "\n",
      "Customer: Bob Johnson, 50 years old, buys gardening supplies occasionally\n",
      "Category: Home & Garden\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample customer data\n",
    "customers = [\n",
    "    \"John Doe, 35 years old, buys electronics frequently\",\n",
    "    \"Jane Smith, 28 years old, purchases cosmetics monthly\",\n",
    "    \"Bob Johnson, 50 years old, buys gardening supplies occasionally\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to categorize customer\n",
    "def categorize_customer(description):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data categorization assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Categorize this customer into one of these categories: Tech Enthusiast, Beauty Lover, Home & Garden. Customer description: {description}. Output in JSON form.\",\n",
    "            },\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# Categorize customers\n",
    "categorized_customers = [categorize_customer(customer) for customer in customers]\n",
    "\n",
    "# Display results\n",
    "for customer, category in zip(customers, categorized_customers):\n",
    "    print(f\"Customer: {customer}\")\n",
    "    print(f\"Category: {category['category']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample location data\n",
    "locations = [\"New York, NY\", \"Los Angeles, California\", \"Chicago, IL, USA\", \"San Fran\"]\n",
    "\n",
    "\n",
    "# Function to normalize location data\n",
    "def normalize_location(location):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a location data normalization assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Normalize this location: {location}. Output in JSON form with city, state, and country.\",\n",
    "            },\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# Normalize locations\n",
    "normalized_locations = [normalize_location(loc) for loc in locations]\n",
    "\n",
    "# Display results\n",
    "for original, normalized in zip(locations, normalized_locations):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Normalized: {normalized}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. References and Further Reading\n",
    "\n",
    "1. OpenAI API Documentation: https://platform.openai.com/docs/\n",
    "2. \"Natural Language Processing with Transformers\" by Lewis Tunstall, Leandro von Werra, and Thomas Wolf\n",
    "3. \"Speech and Language Processing\" by Dan Jurafsky and James H. Martin\n",
    "4. \"Text Mining with R\" by Julia Silge and David Robinson\n",
    "5. \"Applied Text Analysis with Python\" by Benjamin Bengfort, Rebecca Bilbro, and Tony Ojeda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
