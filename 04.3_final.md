**Refactored Code with Additional Improvements and Recommendations**
====================================================================

The provided refactored code has addressed the issues mentioned in the code review. However, to further improve the code, the following suggestions can be considered:

### Additional Improvements

1.  **Input Validation**: In addition to checking if the input is a Pandas DataFrame, consider validating if the DataFrame is empty. This can be done by checking the `shape` attribute of the DataFrame.

2.  **Error Handling for Empty DataFrame**: If the input DataFrame is empty, raise a meaningful error message indicating that the input DataFrame cannot be empty.

3.  **Imputation Techniques**: As mentioned in the additional advice, consider adding more advanced imputation techniques to the `impute_missing_values_with_mean` function or creating separate functions for these techniques.

4.  **Efficient Imputation Methods**: When working with large datasets, consider using more efficient imputation methods, such as using NumPy or Pandas' built-in functions, to reduce computation time.

5.  **Logging Configuration**: The logging configuration can be improved by setting up a more robust logging system, including log levels, handlers, and formatters.

### Refactored Code with Additional Improvements

```python
import pandas as pd
import numpy as np
import logging

def impute_missing_values_with_mean(df: pd.DataFrame) -> pd.DataFrame:
    """
    Imputes missing values in a Pandas DataFrame with the mean of the respective column.

    Args:
        df: The input DataFrame.

    Returns:
        The DataFrame with missing values imputed.

    Raises:
        TypeError: If the input is not a Pandas DataFrame.
        ValueError: If the input DataFrame is empty.
    """
    # Check if the input is a Pandas DataFrame
    if not isinstance(df, pd.DataFrame):
        raise TypeError("Input must be a Pandas DataFrame")

    # Check if the input DataFrame is empty
    if df.empty:
        raise ValueError("Input DataFrame cannot be empty")

    # Create a copy of the input DataFrame to avoid modifying it in-place
    df_imputed = df.copy()

    # Iterate over each column in the DataFrame
    for column in df_imputed.columns:
        # Check if the column contains numeric values
        if pd.api.types.is_numeric_dtype(df_imputed[column]):
            # Calculate the mean of the column, ignoring missing values
            mean_value = df_imputed[column].mean()

            # Replace missing values in the column with the mean
            df_imputed[column] = df_imputed[column].fillna(mean_value)
        else:
            # Log a warning message for non-numeric columns
            logging.warning(f"Column '{column}' is non-numeric and will not be imputed.")

    return df_imputed


def impute_missing_values_with_median(df: pd.DataFrame) -> pd.DataFrame:
    """
    Imputes missing values in a Pandas DataFrame with the median of the respective column.

    Args:
        df: The input DataFrame.

    Returns:
        The DataFrame with missing values imputed.

    Raises:
        TypeError: If the input is not a Pandas DataFrame.
        ValueError: If the input DataFrame is empty.
    """
    # Check if the input is a Pandas DataFrame
    if not isinstance(df, pd.DataFrame):
        raise TypeError("Input must be a Pandas DataFrame")

    # Check if the input DataFrame is empty
    if df.empty:
        raise ValueError("Input DataFrame cannot be empty")

    # Create a copy of the input DataFrame to avoid modifying it in-place
    df_imputed = df.copy()

    # Iterate over each column in the DataFrame
    for column in df_imputed.columns:
        # Check if the column contains numeric values
        if pd.api.types.is_numeric_dtype(df_imputed[column]):
            # Calculate the median of the column, ignoring missing values
            median_value = df_imputed[column].median()

            # Replace missing values in the column with the median
            df_imputed[column] = df_imputed[column].fillna(median_value)
        else:
            # Log a warning message for non-numeric columns
            logging.warning(f"Column '{column}' is non-numeric and will not be imputed.")

    return df_imputed


# Example usage:
if __name__ == "__main__":
    logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')

    data = {
        'A': [1, 2, np.nan, 4, 5],
        'B': [np.nan, 2, 3, 4, 5],
        'C': ['a', 'b', 'c', 'd', 'e']  # Non-numeric column
    }

    df = pd.DataFrame(data)

    print("Original DataFrame:")
    print(df)

    df_imputed_mean = impute_missing_values_with_mean(df)
    df_imputed_median = impute_missing_values_with_median(df)

    print("\nDataFrame with missing values imputed (mean):")
    print(df_imputed_mean)

    print("\nDataFrame with missing values imputed (median):")
    print(df_imputed_median)

```

### Additional Advice

*   Consider using more advanced imputation techniques, such as regression imputation or K-Nearest Neighbors (KNN) imputation.
*   When working with large datasets, consider using more efficient imputation methods, such as using NumPy or Pandas' built-in functions, to reduce computation time.
*   Make sure to validate the imputed values to ensure they are reasonable and accurate.
*   Consider using techniques like cross-validation to evaluate the performance of different imputation methods.
*   Keep in mind that imputation can introduce bias into the dataset if not done carefully, so it's essential to carefully evaluate the results and consider the limitations of the imputation method used.