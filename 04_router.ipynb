{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44f832a",
   "metadata": {},
   "source": [
    "This is the example based on my codebar coaching.\n",
    "\n",
    "We can use an agent to return back the next step as we saw in the JOKE example.\n",
    "\n",
    "We have a list of reports and their uses and a user can ask a question with the agent returning back the most useful report to be run.\n",
    "\n",
    "This can them be processes with more application logic.\n",
    "\n",
    "This is ROUTING or IF/ELSE type decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a2ff2",
   "metadata": {},
   "source": [
    "As we saw in 03 FAQ, we could use this to create a filter for the next agent so that it can be more selective about data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrcra\\Desktop\\OK-django-con-eu\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b03111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For variation use a function to get the LLM client based on the user's choice\n",
    "\n",
    "\n",
    "def get_llm_client(llm_choice):\n",
    "\n",
    "    if llm_choice == \"GROQ\":\n",
    "\n",
    "        client = OpenAI(\n",
    "            base_url=\"https://api.groq.com/openai/v1\",\n",
    "            api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        return client\n",
    "\n",
    "    elif llm_choice == \"OPENAI\":\n",
    "\n",
    "        load_dotenv()  # load environment variables from .env fil\n",
    "\n",
    "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "        return client\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(\"Invalid LLM choice. Please choose 'GROQ' or 'OPENAI'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231605aa-fccb-447e-89cf-8b187444536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY exists and begins sk-proj-1WUVgv...\n",
      "GROQ_API_KEY exists and begins gsk_11hFN1EMfj...\n",
      "LLM_CHOICE: GROQ - MODEL: llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "LLM_CHOICE = \"OPENAI\"\n",
    "LLM_CHOICE = \"GROQ\"\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(f\"OPENAI_API_KEY exists and begins {OPENAI_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY not set\")\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    print(f\"GROQ_API_KEY exists and begins {GROQ_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"GROQ_API_KEY not set\")\n",
    "\n",
    "\n",
    "client = get_llm_client(LLM_CHOICE)\n",
    "if LLM_CHOICE == \"GROQ\":\n",
    "    MODEL = \"llama-3.3-70b-versatile\"\n",
    "else:\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "print(f\"LLM_CHOICE: {LLM_CHOICE} - MODEL: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eacc8a4-4b48-4358-9e06-ce0020041bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A request to the LLM is stateless so we will always need to pass all the data that is needed each time.\n",
    "\n",
    "# `history` is just that - a record of what has gone on before so that the LLM can have context to answer the query.\n",
    "\n",
    "\n",
    "# We will use GRADIO as our UI.\n",
    "def chat(message, history):\n",
    "    # history is part of the gradio ChatInterface and it stores previous answers\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_message}]\n",
    "        # + history ## groq gives error as it adds metadata\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "    # ====================\n",
    "    # AI bit\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL, messages=messages, stream=True, temperature=0.0\n",
    "    )\n",
    "\n",
    "    # Just UI implementation\n",
    "    response = \"\"\n",
    "    for stream_so_far in stream:\n",
    "        response += stream_so_far.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f91b414-8bab-472d-b9c9-3fa51259bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a report selection agent. \n",
    "You are very good at returning the best report to answer a user's question. \n",
    "For example, if a user wants a joke, you reply with |TOOL: **get_joke**|\n",
    "Another example, if they want a **TOTAL SALES** report then |TOOL: **get_sales**| would be the best report.\n",
    "We use this format so we can extract out reports from your answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d57e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** just for bold in front end but does add some importance too.\n",
    "\n",
    "REPORTS = [\n",
    "    \"For information on Sprints use this tool => **get_sprint**.\",\n",
    "    \"For information on Django Conference Venue and loation use this tool => **get_conf_info**\",\n",
    "    \"For information on Grants and Support use this tool => **get_grant_info**\",\n",
    "    \"For information on Talks and workshops use this tool => **get_talk_info**\",\n",
    "    \"For information on Sprints use this tool => **get_sprint**.\",\n",
    "    \"For weather use this tool => **get_weather**.\",\n",
    "    \"For hotel booking use this tool => **get_hotel_booking**.\",\n",
    "    \"For car hire use this tool => **get_car_hire**.\",\n",
    "    \"For flight booking use this tool => **get_flight**.\",\n",
    "    \"For total sales use this tool => **get_sales**.\",\n",
    "    \"For site statistics use this tool => **get_site_statistics**.\",\n",
    "    \"For jokes use this tool => **get_joke**.\",\n",
    "    \"To add two numbers use this tool => **get_adder**.\",\n",
    "    \"To compute loss function => **get_loss**.\",\n",
    "    \"To critique an article prior to publication but not after publication use this tool => **get_article_review**.\",\n",
    "    \"For all other requests use this tool => **customer_service_agent**.\",\n",
    "]\n",
    "\n",
    "# Again, 'character and instruction' along with knowledge\n",
    "system_message += \"\\n\" + \"\\n\".join(REPORTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef08971",
   "metadata": {},
   "source": [
    "If we combine this ROUTER as a precursor to the FAQ pattern, we one agent selecting the domain, and another agent answering the question.\n",
    "\n",
    "This is a MULTI-AGENT system - we can have a range of design patterns that can be used to create a MULTI-AGENT system.\n",
    "\n",
    "<img src=\"./images/antrhopic-workflows.png\" width=700px>\n",
    "\n",
    "https://www.anthropic.com/engineering/building-effective-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': \"\\nYou are a report selection agent. \\nYou are very good at returning the best report to answer a user's question. \\nFor example, if a user wants a joke, you reply with |TOOL: **get_joke**|\\nAnother example, if they want a **TOTAL SALES** report then |TOOL: **get_sales**| would be the best report.\\nWe use this format so we can extract out reports from your answer.\\n\\nFor information on Sprints use this tool => **get_sprint**.\\nFor information on Django Conference Venue and loation use this tool => **get_conf_info**\\nFor information on Grants and Support use this tool => **get_grant_info**\\nFor information on Talks and workshops use this tool => **get_talk_info**\\nFor information on Sprints use this tool => **get_sprint**.\\nFor weather use this tool => **get_weather**.\\nFor hotel booking use this tool => **get_hotel_booking**.\\nFor car hire use this tool => **get_car_hire**.\\nFor flight booking use this tool => **get_flight**.\\nFor total sales use this tool => **get_sales**.\\nFor site statistics use this tool => **get_site_statistics**.\\nFor jokes use this tool => **get_joke**.\\nTo add two numbers use this tool => **get_adder**.\\nTo compute loss function => **get_loss**.\\nTo critique an article prior to publication but not after publication use this tool => **get_article_review**.\\nFor all other requests use this tool => **customer_service_agent**.\"}, {'role': 'user', 'content': 'infor on django sprints'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': None, 'content': 'infor on django sprints', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': '|TOOL: **get_sprint**|', 'options': None}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': \"\\nYou are a report selection agent. \\nYou are very good at returning the best report to answer a user's question. \\nFor example, if a user wants a joke, you reply with |TOOL: **get_joke**|\\nAnother example, if they want a **TOTAL SALES** report then |TOOL: **get_sales**| would be the best report.\\nWe use this format so we can extract out reports from your answer.\\n\\nFor information on Sprints use this tool => **get_sprint**.\\nFor information on Django Conference Venue and loation use this tool => **get_conf_info**\\nFor information on Grants and Support use this tool => **get_grant_info**\\nFor information on Talks and workshops use this tool => **get_talk_info**\\nFor information on Sprints use this tool => **get_sprint**.\\nFor weather use this tool => **get_weather**.\\nFor hotel booking use this tool => **get_hotel_booking**.\\nFor car hire use this tool => **get_car_hire**.\\nFor flight booking use this tool => **get_flight**.\\nFor total sales use this tool => **get_sales**.\\nFor site statistics use this tool => **get_site_statistics**.\\nFor jokes use this tool => **get_joke**.\\nTo add two numbers use this tool => **get_adder**.\\nTo compute loss function => **get_loss**.\\nTo critique an article prior to publication but not after publication use this tool => **get_article_review**.\\nFor all other requests use this tool => **customer_service_agent**.\"}, {'role': 'user', 'content': 'temp in dublin'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': None, 'content': 'infor on django sprints', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': '|TOOL: **get_sprint**|', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'temp in dublin', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': '|TOOL: **get_weather**|', 'options': None}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': \"\\nYou are a report selection agent. \\nYou are very good at returning the best report to answer a user's question. \\nFor example, if a user wants a joke, you reply with |TOOL: **get_joke**|\\nAnother example, if they want a **TOTAL SALES** report then |TOOL: **get_sales**| would be the best report.\\nWe use this format so we can extract out reports from your answer.\\n\\nFor information on Sprints use this tool => **get_sprint**.\\nFor information on Django Conference Venue and loation use this tool => **get_conf_info**\\nFor information on Grants and Support use this tool => **get_grant_info**\\nFor information on Talks and workshops use this tool => **get_talk_info**\\nFor information on Sprints use this tool => **get_sprint**.\\nFor weather use this tool => **get_weather**.\\nFor hotel booking use this tool => **get_hotel_booking**.\\nFor car hire use this tool => **get_car_hire**.\\nFor flight booking use this tool => **get_flight**.\\nFor total sales use this tool => **get_sales**.\\nFor site statistics use this tool => **get_site_statistics**.\\nFor jokes use this tool => **get_joke**.\\nTo add two numbers use this tool => **get_adder**.\\nTo compute loss function => **get_loss**.\\nTo critique an article prior to publication but not after publication use this tool => **get_article_review**.\\nFor all other requests use this tool => **customer_service_agent**.\"}, {'role': 'user', 'content': 'profit of our company'}]\n"
     ]
    }
   ],
   "source": [
    "# We use Gradio for a chat interface\n",
    "# prompt: I am want a plane to Rome then an auto to Paris\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
