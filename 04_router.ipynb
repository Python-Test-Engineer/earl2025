{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44f832a",
   "metadata": {},
   "source": [
    "This is the example based on my codebar coaching.\n",
    "\n",
    "We can use an agent to return back the next step as we saw in the JOKE example.\n",
    "\n",
    "We have a list of reports and their uses and a user can ask a question with the agent returning back the most useful report to be run.\n",
    "\n",
    "This can them be processes with more application logic.\n",
    "\n",
    "This is ROUTING or IF/ELSE type decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a2ff2",
   "metadata": {},
   "source": [
    "As we saw in 03 FAQ, we could use this to create a filter for the next agent so that it can be more selective about data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrcra\\Desktop\\pydata-southampton\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b03111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For variation use a function to get the LLM client based on the user's choice\n",
    "\n",
    "\n",
    "def get_llm_client(llm_choice):\n",
    "\n",
    "    if llm_choice == \"GROQ\":\n",
    "\n",
    "        client = OpenAI(\n",
    "            base_url=\"https://api.groq.com/openai/v1\",\n",
    "            api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        return client\n",
    "\n",
    "    elif llm_choice == \"OPENAI\":\n",
    "\n",
    "        load_dotenv()  # load environment variables from .env fil\n",
    "\n",
    "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "        return client\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(\"Invalid LLM choice. Please choose 'GROQ' or 'OPENAI'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231605aa-fccb-447e-89cf-8b187444536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY exists and begins sk-proj-RRFXIc...\n",
      "GROQ_API_KEY exists and begins gsk_YAmC2ydBhH...\n",
      "LLM_CHOICE: GROQ - MODEL: llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "LLM_CHOICE = \"OPENAI\"\n",
    "LLM_CHOICE = \"GROQ\"\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(f\"OPENAI_API_KEY exists and begins {OPENAI_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY not set\")\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    print(f\"GROQ_API_KEY exists and begins {GROQ_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"GROQ_API_KEY not set\")\n",
    "\n",
    "\n",
    "client = get_llm_client(LLM_CHOICE)\n",
    "if LLM_CHOICE == \"GROQ\":\n",
    "    MODEL = \"llama-3.3-70b-versatile\"\n",
    "else:\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "print(f\"LLM_CHOICE: {LLM_CHOICE} - MODEL: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eacc8a4-4b48-4358-9e06-ce0020041bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A request to the LLM is stateless so we will always need to pass all the data that is needed each time.\n",
    "\n",
    "# `history` is just that - a record of what has gone on before so that the LLM can have context to answer the query.\n",
    "\n",
    "\n",
    "# We will use GRADIO as our UI.\n",
    "def chat(message, history):\n",
    "    # history is part of the gradio ChatInterface and it stores previous answers\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_message}]\n",
    "        # + history ## groq gives error as it adds metadata\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "    # ====================\n",
    "    # AI bit\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL, messages=messages, stream=True, temperature=0.0\n",
    "    )\n",
    "\n",
    "    # Just UI implementation\n",
    "    response = \"\"\n",
    "    for stream_so_far in stream:\n",
    "        response += stream_so_far.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d57e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To clean data use |DATA_CLEANING_AGENT|\n",
      "Total number of data_analysis_agents: 35\n"
     ]
    }
   ],
   "source": [
    "# ** just for bold in front end but does add some importance too.\n",
    "\n",
    "data_analysis_agents = [\n",
    "    \"To clean data use |DATA_CLEANING_AGENT|\",\n",
    "    \"To run analysis on data types use |DATA_TYPES_AGENT|\",\n",
    "    \"To do feature engineering use |FEATURE_ENGINEERING_AGENT|\",\n",
    "    \"To handle missing values use |MISSING_DATA_AGENT|\",\n",
    "    \"To detect outliers use |OUTLIER_DETECTION_AGENT|\",\n",
    "    \"To normalize or standardize features use |SCALING_AGENT|\",\n",
    "    \"To perform correlation analysis use |CORRELATION_AGENT|\",\n",
    "    \"To create visualizations use |VISUALIZATION_AGENT|\",\n",
    "    \"To run statistical tests use |STATISTICAL_TESTING_AGENT|\",\n",
    "    \"To perform dimensionality reduction use |DIMENSION_REDUCTION_AGENT|\",\n",
    "    \"To segment data into clusters use |CLUSTERING_AGENT|\",\n",
    "    \"To build predictive models use |PREDICTIVE_MODELING_AGENT|\",\n",
    "    \"To evaluate model performance use |MODEL_EVALUATION_AGENT|\",\n",
    "    \"To optimize hyperparameters use |HYPERPARAMETER_TUNING_AGENT|\",\n",
    "    \"To handle imbalanced datasets use |CLASS_IMBALANCE_AGENT|\",\n",
    "    \"To implement time series analysis use |TIME_SERIES_AGENT|\",\n",
    "    \"To perform text analysis use |TEXT_ANALYTICS_AGENT|\",\n",
    "    \"To extract insights from geospatial data use |GEOSPATIAL_ANALYSIS_AGENT|\",\n",
    "    \"To process large datasets use |BIG_DATA_PROCESSING_AGENT|\",\n",
    "    \"To create data pipelines use |DATA_PIPELINE_AGENT|\",\n",
    "    \"To generate synthetic data use |SYNTHETIC_DATA_AGENT|\",\n",
    "    \"To implement cross-validation use |CROSS_VALIDATION_AGENT|\",\n",
    "    \"To interpret complex models use |MODEL_INTERPRETATION_AGENT|\",\n",
    "    \"To detect data drift use |DATA_DRIFT_AGENT|\",\n",
    "    \"To run A/B tests use |AB_TESTING_AGENT|\",\n",
    "    \"To prepare data for machine learning use |ML_PREPROCESSING_AGENT|\",\n",
    "    \"To create ensemble models use |ENSEMBLE_MODELING_AGENT|\",\n",
    "    \"To perform anomaly detection use |ANOMALY_DETECTION_AGENT|\",\n",
    "    \"To optimize SQL queries use |SQL_OPTIMIZATION_AGENT|\",\n",
    "    \"To create interactive dashboards use |DASHBOARD_CREATION_AGENT|\",\n",
    "    \"To extract features from images use |IMAGE_FEATURE_AGENT|\",\n",
    "    \"To implement natural language processing use |NLP_AGENT|\",\n",
    "    \"To perform sentiment analysis use |SENTIMENT_ANALYSIS_AGENT|\",\n",
    "    \"To do automated feature selection use |FEATURE_SELECTION_AGENT|\",\n",
    "    \"To generate reports automatically use |AUTOMATED_REPORTING_AGENT|\",\n",
    "]\n",
    "\n",
    "# Access individual tools\n",
    "print(data_analysis_agents[0])  # Prints the first tool\n",
    "\n",
    "# Count total number of data_analysis_agents\n",
    "print(f\"Total number of data_analysis_agents: {len(data_analysis_agents)}\")\n",
    "# Again, 'character and instruction' along with knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df916ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a skilled data analyst and data engineer. When asked a question, you will respond with the most relevant data analysis agent from the list below.\n",
    "\n",
    "The data analysis agents are:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7377e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\n\" + \"\\n\".join(data_analysis_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4acf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef08971",
   "metadata": {},
   "source": [
    "If we combine this ROUTER as a precursor to the FAQ pattern, we one agent selecting the domain, and another agent answering the question.\n",
    "\n",
    "This is a MULTI-AGENT system - we can have a range of design patterns that can be used to create a MULTI-AGENT system.\n",
    "\n",
    "<img src=\"./images/antrhopic-workflows.png\" width=700px>\n",
    "\n",
    "https://www.anthropic.com/engineering/building-effective-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': '\\nYou are a skilled data analyst and data engineer. When asked a question, you will respond with the most relevant data analysis agent from the list below.\\n\\nThe data analysis agents are:\\n\\n\\nTo clean data use |DATA_CLEANING_AGENT|\\nTo run analysis on data types use |DATA_TYPES_AGENT|\\nTo do feature engineering use |FEATURE_ENGINEERING_AGENT|\\nTo handle missing values use |MISSING_DATA_AGENT|\\nTo detect outliers use |OUTLIER_DETECTION_AGENT|\\nTo normalize or standardize features use |SCALING_AGENT|\\nTo perform correlation analysis use |CORRELATION_AGENT|\\nTo create visualizations use |VISUALIZATION_AGENT|\\nTo run statistical tests use |STATISTICAL_TESTING_AGENT|\\nTo perform dimensionality reduction use |DIMENSION_REDUCTION_AGENT|\\nTo segment data into clusters use |CLUSTERING_AGENT|\\nTo build predictive models use |PREDICTIVE_MODELING_AGENT|\\nTo evaluate model performance use |MODEL_EVALUATION_AGENT|\\nTo optimize hyperparameters use |HYPERPARAMETER_TUNING_AGENT|\\nTo handle imbalanced datasets use |CLASS_IMBALANCE_AGENT|\\nTo implement time series analysis use |TIME_SERIES_AGENT|\\nTo perform text analysis use |TEXT_ANALYTICS_AGENT|\\nTo extract insights from geospatial data use |GEOSPATIAL_ANALYSIS_AGENT|\\nTo process large datasets use |BIG_DATA_PROCESSING_AGENT|\\nTo create data pipelines use |DATA_PIPELINE_AGENT|\\nTo generate synthetic data use |SYNTHETIC_DATA_AGENT|\\nTo implement cross-validation use |CROSS_VALIDATION_AGENT|\\nTo interpret complex models use |MODEL_INTERPRETATION_AGENT|\\nTo detect data drift use |DATA_DRIFT_AGENT|\\nTo run A/B tests use |AB_TESTING_AGENT|\\nTo prepare data for machine learning use |ML_PREPROCESSING_AGENT|\\nTo create ensemble models use |ENSEMBLE_MODELING_AGENT|\\nTo perform anomaly detection use |ANOMALY_DETECTION_AGENT|\\nTo optimize SQL queries use |SQL_OPTIMIZATION_AGENT|\\nTo create interactive dashboards use |DASHBOARD_CREATION_AGENT|\\nTo extract features from images use |IMAGE_FEATURE_AGENT|\\nTo implement natural language processing use |NLP_AGENT|\\nTo perform sentiment analysis use |SENTIMENT_ANALYSIS_AGENT|\\nTo do automated feature selection use |FEATURE_SELECTION_AGENT|\\nTo generate reports automatically use |AUTOMATED_REPORTING_AGENT|'}, {'role': 'user', 'content': 'i need to test which of my appraoches is best'}]\n"
     ]
    }
   ],
   "source": [
    "# We use Gradio for a chat interface\n",
    "# prompt: I am want a plane to Rome then an auto to Paris\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
