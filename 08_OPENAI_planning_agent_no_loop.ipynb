{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/react.png\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB This talk is less about creating Agentic Apps as it is to demystify and simplify what AI Agents are. In this regard, this example may seem involved on seeing it the fist time. Look for where we have Day To Day Python and where we have AI, so that you may see that AI Agents are 'just' Python with LLM calls.\n",
    "\n",
    "\n",
    "This example shows planning using ReAct - Reason and Act.\n",
    "\n",
    "Essentially, we pass the output of each step to the next request to the LLM, like we did in reflection but adding in tool calling.\n",
    "\n",
    "PLANNING is equivalent to REFLECTION and TOOL CALLING\n",
    "\n",
    "We continue to do this until we get to the end as specified in the prompt, which we will see later in the code.\n",
    "\n",
    "By giving examples, we are using Multi-Shot Prompting. If we gave just one example then this is called Single Shot Prompting, and no examples is Zero Shot Prompting.\n",
    "\n",
    "We may go through it iteratively in this notebook but the next file `20_planning_agent_w_loop.py` has this as a Class containing a loop and form a high level view is easy to grasp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB This example may need to be run through a number of times to get it to sink in so just focus on the high level view.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will ask the agent to get the total price including VAT for a product.\n",
    "\n",
    "It will have two tools:\n",
    "\n",
    "1. get_product_price(product)\n",
    "2. calculate_total(price * 1.2 VAT)\n",
    "\n",
    "We will ask it to get the total price for say a laptop. It will need to REASON how to do this, take ACTION, get an OBSERVATION and repeat this loop until it gets an ANSWER.\n",
    "\n",
    "This script has been detailed in the SYSTEM PROMPT.\n",
    "\n",
    "It is essentially a loop passing back in the former output until it thinks it has an ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Let's not get focused on the code implementation but rather see the overall flow pattern. We can digest it more fully offline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_client(llm_choice):\n",
    "    if llm_choice == \"GROQ\":\n",
    "        client = OpenAI(\n",
    "            base_url=\"https://api.groq.com/openai/v1\",\n",
    "            api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "        )\n",
    "        return client\n",
    "    elif llm_choice == \"OPENAI\":\n",
    "        load_dotenv()  # load environment variables from .env fil\n",
    "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "        return client\n",
    "    else:\n",
    "        raise ValueError(\"Invalid LLM choice. Please choose 'GROQ' or 'OPENAI'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY exists and begins sk-proj-1WUVgv...\n",
      "GROQ_API_KEY exists and begins gsk_11hFN1EMfj...\n",
      "LLM_CHOICE: OPENAI - MODEL: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "LLM_CHOICE = \"OPENAI\"\n",
    "# breaks with Groq as the output is not in the right format. This shows the need for structured output whcih we will see in 10_groq_strucutred _output.ipynb\n",
    "# LLM_CHOICE = \"GROQ\"\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(f\"OPENAI_API_KEY exists and begins {OPENAI_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY not set\")\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    print(f\"GROQ_API_KEY exists and begins {GROQ_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"GROQ_API_KEY not set\")\n",
    "\n",
    "\n",
    "client = get_llm_client(LLM_CHOICE)\n",
    "if LLM_CHOICE == \"GROQ\":\n",
    "    MODEL = \"llama-3.3-70b-versatile\"\n",
    "else:\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "print(f\"LLM_CHOICE: {LLM_CHOICE} - MODEL: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make a class to show the ReAct (Reason - Act) pattern\n",
    "class PlanningAgent:\n",
    "    def __init__(self, client, model=MODEL, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "            result = self.execute()\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "            return result\n",
    "        else:\n",
    "            print(\"NO MESSAGE\")\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(model=MODEL, messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of THOUGHT, ACTION, OBSERVATION.\n",
    "\n",
    "You have two tools available for your ACTIONS - calculate_total and get_product_price so that you can get the total price of an item requested by the user.\n",
    "\n",
    "# 1. calculate_total:\n",
    "\n",
    "if amount = 200\n",
    "then calculate_total(amount)\n",
    "return amount * 1.2\n",
    "\n",
    "Runs the calculate_total function and returns a JSON FORMAT output as follows:\n",
    "{\"result\": 240, \"fn\": \"calculate_total\", \"next\": \"PAUSE\"}\n",
    "\n",
    "# 2. get_product_price:\n",
    "\n",
    "This uses the get_product_price function and passes in the value of the product\n",
    "e.g. get_product_price('bike')\n",
    "\n",
    "This uses the get_product_price with a product = 'bike', finds the price of the bike and then returns a JSON FORMAT output as follows:\n",
    "{\"result\": 200, \"fn\": \"get_product_price\", \"next\": \"PAUSE\"}\n",
    "\n",
    "Here is an example session:\n",
    "\n",
    "User Question: What is total cost of a bike including VAT?\n",
    "\n",
    "AI Response: THOUGHT: I need to find the cost of a bike|ACTION|get_product_price|bike\n",
    "\n",
    "You will be called again with the result of get_product_price as the OBSERVATION and will have OBSERVATION|200 sent as another LLM query along with previous messages.\n",
    "\n",
    "Then the next message will be:\n",
    "\n",
    "THOUGHT: I need to calculate the total including the VAT|ACTION|calculate_total|200\n",
    "\n",
    "The result wil be passed as another query as OBSERVATION|240 along with previous messages.\n",
    "\n",
    "If you have the ANSWER, output it as the ANSWER in this format:\n",
    "\n",
    "ANSWER|The price of the bike including VAT is 240\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total(amount) -> float:\n",
    "    return int(amount * 1.2)\n",
    "\n",
    "\n",
    "def get_product_price(product):\n",
    "    if product == \"bike\":\n",
    "        return 100\n",
    "    if product == \"tv\":\n",
    "        return 200\n",
    "    if product == \"laptop\":\n",
    "        return 300\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PlanningAgent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THOUGHT: I need to find the cost of a laptop|ACTION|get_product_price|laptop\n"
     ]
    }
   ],
   "source": [
    "result = agent(\"What is cost of a laptop including the VAT?\")\n",
    "# result = agent(\"What is cost of a bike including the VAT?\")\n",
    "# result = agent(\"What is cost of a tv including the VAT?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the result to the next call, having extracted the function name and arguments from the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION - get_product_price |  ARGUMENT - laptop\n"
     ]
    }
   ],
   "source": [
    "next = result.split(\"|\")\n",
    "next_function = next[2]\n",
    "next_arg = next[3]\n",
    "print(f\"FUNCTION - {next_function} |  ARGUMENT - {next_arg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# We manually run the tool - in the .py file example we do this programatically.\n",
    "# This is for illustrative purposes.\n",
    "\n",
    "if next_function == \"get_product_price\":\n",
    "    result = get_product_price(next_arg)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observation|300'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = f\"Observation|{result}\"\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THOUGHT: I need to calculate the total including the VAT|ACTION|calculate_total|300\n"
     ]
    }
   ],
   "source": [
    "result = agent(next_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION - calculate_total |  ARGUMENT - 300\n"
     ]
    }
   ],
   "source": [
    "next = result.split(\"|\")\n",
    "next_function = next[2]\n",
    "next_arg = int(next[3])\n",
    "print(f\"FUNCTION - {next_function} |  ARGUMENT - {next_arg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "# We manually run the tool - in the .py file example we do this programatically.\n",
    "# This is for illustrative purposes.\n",
    "\n",
    "if next_function == \"calculate_total\":\n",
    "    result = calculate_total(next_arg)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OBSERVATION|360'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now create a new user prompt with the result and in the format specified in the prompt engineered system prompt\n",
    "next_prompt = f\"OBSERVATION|{result}\"\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER|The price of the laptop including VAT is 360\n"
     ]
    }
   ],
   "source": [
    "# We now pass the OBSERVATION and RESULT as a new user query that is appended to all the previous messages.\n",
    "result = agent(next_prompt)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
